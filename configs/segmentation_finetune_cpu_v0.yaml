# Fine-tuning Configuration for Small Segmentation Dataset (CPU Training)
# Optimized for small dataset (15 images) with CPU training

experiment:
  name: segmentation_markers_finetune
  seed: 42

data:
  dataset_type: segmentation
  data_dir: c:\Facultate\segmentation_markers\dataset\train\images
  mask_dir: c:\Facultate\segmentation_markers\dataset\train\masks
  val_data_dir: c:\Facultate\segmentation_markers\dataset\val\images
  val_mask_dir: c:\Facultate\segmentation_markers\dataset\val\masks
  num_classes: 2  # Background and markers (binary segmentation)
  class_names: ['background', 'markers']
  mask_format: 'rgb'
  train_split: 1.0  # Use all training data
  val_split: 1.0    # Use all validation data
  test_split: 0.0

dataloader:
  batch_size: 2     # Small batch size for CPU and small dataset
  num_workers: 0    # Use 0 for CPU training to avoid multiprocessing issues
  pin_memory: false # Disable for CPU
  persistent_workers: false
  prefetch_factor: 2

model:
  backbone: timm_resnet50
  pretrained: true
  freeze_backbone: false  # Fine-tune the entire model

loss:
  name: combined
  ce_weight: 1.0
  dice_weight: 1.0
  focal_weight: 0.0
  lovasz_weight: 0.0
  ignore_index: 255

optimizer:
  name: adamw
  lr: 5e-5  # Lower learning rate for fine-tuning
  weight_decay: 1e-4
  betas: [0.9, 0.999]
  eps: 1e-8

scheduler:
  name: cosine_warmup
  warmup_epochs: 2
  total_epochs: 50
  min_lr: 1e-6

training:
  epochs: 50
  amp: false        # Disable AMP for CPU training
  gradient_clip_norm: 1.0
  gradient_accumulation_steps: 4  # Accumulate gradients to simulate larger batch size

metrics:
  task: segmentation
  num_classes: 2
  ignore_index: 255

callbacks:
  checkpoint:
    monitor: val_loss
    mode: min
    save_top_k: 3
    enabled: true
  
  early_stopping:
    monitor: val_loss
    mode: min
    patience: 10  # Stop early if no improvement
    enabled: true
  
  sample_visualizer:
    num_samples: 4
    save_every_n_epochs: 5
    enabled: true
  
  confusion_matrix:
    save_every_n_epochs: 5
    enabled: true
  
  learning_rate:
    save_every_n_epochs: 5
    enabled: true

transforms:
  resize: 256      # Smaller input size for CPU training
  horizontal_flip: true
  vertical_flip: false
  rotation: 10
  shift_scale_rotate: true
  elastic_transform: false  # Disable heavy augmentations
  grid_distortion: false
  color_jitter: true
  gaussian_noise: false
  gaussian_blur: false
  normalize:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  use_albumentations: true
